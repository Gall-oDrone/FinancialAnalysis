{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56421fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Storage')\n",
    "\n",
    "import pgConn\n",
    "import PostgresSQL_table_queries\n",
    "import CloudStorage\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17993c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the database successful!\n",
      "Table name set to: historical\n"
     ]
    }
   ],
   "source": [
    "pg_conn = pgConn.PgConn(\"historical\")\n",
    "df = pg_conn.get_stocks_prices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260d7bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>book</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://finance.yahoo.com</td>\n",
       "      <td>tusd-btc</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>102207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://finance.yahoo.com</td>\n",
       "      <td>tusd-btc</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>74850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://finance.yahoo.com</td>\n",
       "      <td>tusd-btc</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>34264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://finance.yahoo.com</td>\n",
       "      <td>tusd-btc</td>\n",
       "      <td>2023-08-06</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>29283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://finance.yahoo.com</td>\n",
       "      <td>tusd-btc</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>78352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ref      book        date      open      high  \\\n",
       "0  https://finance.yahoo.com  tusd-btc  2023-08-09  0.000034  0.000034   \n",
       "1  https://finance.yahoo.com  tusd-btc  2023-08-08  0.000034  0.000034   \n",
       "2  https://finance.yahoo.com  tusd-btc  2023-08-07  0.000034  0.000034   \n",
       "3  https://finance.yahoo.com  tusd-btc  2023-08-06  0.000034  0.000034   \n",
       "4  https://finance.yahoo.com  tusd-btc  2023-08-05  0.000034  0.000034   \n",
       "\n",
       "        low     close  adj_close  volume  \n",
       "0  0.000034  0.000034   0.000034  102207  \n",
       "1  0.000034  0.000034   0.000034   74850  \n",
       "2  0.000034  0.000034   0.000034   34264  \n",
       "3  0.000034  0.000034   0.000034   29283  \n",
       "4  0.000034  0.000034   0.000034   78352  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1838f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ref          83723\n",
       "book         83723\n",
       "date         83723\n",
       "open         83723\n",
       "high         83723\n",
       "low          83723\n",
       "close        83723\n",
       "adj_close    83723\n",
       "volume       83723\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3f97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of values in 'date' column: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "date_column_type = df['date'].dtype\n",
    "print(\"Type of values in 'date' column:\", date_column_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be01ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataETL():\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "            self.df = dataframe\n",
    "    \n",
    "    class Export():\n",
    "        def __init__(self, dataframe):\n",
    "            self.cloudProvider = CloudStorage.CloudStorageProvider()\n",
    "            self.df = dataframe\n",
    "            \n",
    "        def export_stocks_to_s3(self, bucket_name, prefix_path):\n",
    "            # Initialize AWS storage\n",
    "            aws_storage = self.cloudProvider.AWS()\n",
    "\n",
    "            # Create a new bucket\n",
    "            aws_storage.create_bucket(bucket_name)\n",
    "\n",
    "            # Upload DataFrame with datetime subfolder structure\n",
    "            aws_storage.upload_dataframe_with_timestamp(self.df, bucket_name, prefix_path)\n",
    "            \n",
    "        def export_stocks_to_s3_full_file(self, bucket_name, prefix_path, filename):\n",
    "            # Initialize AWS storage\n",
    "            aws_storage = self.cloudProvider.AWS()\n",
    "            aws_storage.upload_dataframe_to_csv(self.df, bucket_name, filename, prefix_path)\n",
    "            \n",
    "    class Ingestion():\n",
    "        \n",
    "        def __init__(self, dataframe):\n",
    "            self.df = dataframe\n",
    "            self.cloudProvider = CloudStorage.CloudStorageProvider()\n",
    "            \n",
    "        def get_full_data_csv_file(self, bucket_name, prefix_path):\n",
    "            # Initialize AWS storage\n",
    "            aws_storage = self.cloudProvider.AWS()\n",
    "            return aws_storage.get_csv_from_specific_folder(bucket_name, prefix_path)\n",
    "    \n",
    "    class Process():\n",
    "        \n",
    "        def __init__(self, dataframe):\n",
    "            self.df = dataframe\n",
    "        \n",
    "        def getData():\n",
    "            self.df = pg_conn.get_financial_news()\n",
    "        \n",
    "        def filter_by_current_date(self):\n",
    "            # Get the current date as a string\n",
    "            today_date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "            # Extract the year, month, and day from the current date string\n",
    "            current_year, current_month, current_day = today_date_str.split('-')\n",
    "\n",
    "            # Filter the DataFrame by comparing the substrings of the datetime column\n",
    "            filtered_df = self.df[self.df['date'].str.startswith(f'{current_year}-{current_month}-{current_day}')]\n",
    "\n",
    "            return filtered_df\n",
    "        \n",
    "        def filter_by_date_range(self, df, start_date, end_date):\n",
    "            # Convert start_date and end_date strings to datetime objects\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            # Filter by date range\n",
    "            filtered_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "            return filtered_df\n",
    "        \n",
    "        def filter_by_book(self, df, book=None):\n",
    "            # Filter by book if specified\n",
    "            if book is not None:\n",
    "                filtered_df = df[df['book'] == book]\n",
    "            return filtered_df\n",
    "        \n",
    "        def get_unique_by_date(self, df):\n",
    "            # Sort the DataFrame by 'date' in descending order\n",
    "            df_sorted = df.sort_values(by='date', ascending=False)\n",
    "\n",
    "            # Drop duplicates, keeping only the first occurrence for each unique combination of book and date\n",
    "            df_unique_latest = df_sorted.drop_duplicates(subset=['book', 'date'])\n",
    "            df_unique_latest.count()\n",
    "            return df_unique_latest\n",
    "            \n",
    "    class Transform():\n",
    "        def extractStopWords():\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661d2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_BY_CURRENT_DATE = False\n",
    "FILTER_BY_RANGE_DATE = True\n",
    "FILTER_BY_BOOK_DATE = False\n",
    "# TODO 2017-2016\n",
    "etl = DataETL(df)\n",
    "etl_process = etl.Process(etl.df)\n",
    "uniqued_df = etl_process.get_unique_by_date(etl_process.df)\n",
    "processed_df = uniqued_df\n",
    "\n",
    "if FILTER_BY_CURRENT_DATE == True:\n",
    "    processed_df = etl_process.filter_by_current_date(uniqued_df)\n",
    "    processed_df.head()\n",
    "elif FILTER_BY_RANGE_DATE == True:\n",
    "    start_date='2024-05-20'\n",
    "    end_date='2024-05-20'\n",
    "    processed_df = etl_process.filter_by_date_range(uniqued_df, start_date, end_date)\n",
    "    processed_df.head()\n",
    "elif FILTER_BY_BOOK_DATE == True:\n",
    "    processed_df = etl_process.filter_by_current_date(uniqued_df)\n",
    "    processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8d084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'test-financial-stocks-bucket' created successfully.\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/eth-btc/2024/05/20/20240520-eth-btc.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/tusd-btc/2024/05/20/20240520-tusd-btc.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/lrc-usd/2024/05/20/20240520-lrc-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/ltc-usd/2024/05/20/20240520-ltc-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/near-usd/2024/05/20/20240520-near-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/trx-usd/2024/05/20/20240520-trx-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/ldo-usd/2024/05/20/20240520-ldo-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/xlm-usd/2024/05/20/20240520-xlm-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/paxg-usd/2024/05/20/20240520-paxg-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/avax-usd/2024/05/20/20240520-avax-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/bat-usd/2024/05/20/20240520-bat-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/bch-usd/2024/05/20/20240520-bch-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/btc-usd/2024/05/20/20240520-btc-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/sand-usd/2024/05/20/20240520-sand-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/qnt-usd/2024/05/20/20240520-qnt-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/link-usd/2024/05/20/20240520-link-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/bal-usd/2024/05/20/20240520-bal-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/axs-usd/2024/05/20/20240520-axs-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/shib-usd/2024/05/20/20240520-shib-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/sol-usd/2024/05/20/20240520-sol-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/algo-usd/2024/05/20/20240520-algo-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/tigres-usd/2024/05/20/20240520-tigres-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/bar-usd/2024/05/20/20240520-bar-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/psg-usd/2024/05/20/20240520-psg-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/doge-usd/2024/05/20/20240520-doge-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/atom-usd/2024/05/20/20240520-atom-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/dot-usd/2024/05/20/20240520-dot-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/snx-usd/2024/05/20/20240520-snx-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/omg-usd/2024/05/20/20240520-omg-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/xrp-usd/2024/05/20/20240520-xrp-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/eth-usd/2024/05/20/20240520-eth-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/mana-usd/2024/05/20/20240520-mana-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/uni-usd/2024/05/20/20240520-uni-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/chz-usd/2024/05/20/20240520-chz-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/dydx-usd/2024/05/20/20240520-dydx-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/yfi-usd/2024/05/20/20240520-yfi-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/aave-usd/2024/05/20/20240520-aave-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/matic-usd/2024/05/20/20240520-matic-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/gala-usd/2024/05/20/20240520-gala-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/sushi-usd/2024/05/20/20240520-sushi-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/mkr-usd/2024/05/20/20240520-mkr-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/ada-usd/2024/05/20/20240520-ada-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/ape-usd/2024/05/20/20240520-ape-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/crv-usd/2024/05/20/20240520-crv-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/ftm-usd/2024/05/20/20240520-ftm-usd.csv'\n",
      "Data uploaded to S3 bucket 'test-financial-stocks-bucket' under folder 'stocks/crypto/enj-usd/2024/05/20/20240520-enj-usd.csv'\n"
     ]
    }
   ],
   "source": [
    "etl_export = etl.Export(processed_df)\n",
    "bucket_name = \"test-financial-stocks-bucket\"\n",
    "prefix_path = \"stocks/crypto\"\n",
    "post_full_csv = False\n",
    "post_to_s3 = True\n",
    "now = datetime.now()\n",
    "filename = f\"{now.year}-{now.month:02}-{now.day:02}_full_record\"\n",
    "\n",
    "if post_to_s3 == True:\n",
    "    etl_export.export_stocks_to_s3(bucket_name, prefix_path)\n",
    "if post_full_csv == True:\n",
    "    etl_export.export_stocks_to_s3_full_file(bucket_name, prefix_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af32c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_data = False\n",
    "get_full_file = True\n",
    "df_from_file = None\n",
    "\n",
    "if ingest_data == True:\n",
    "    etl_ingestion = etl.Ingestion(etl.df)\n",
    "    bucket_name = \"test-financial-stocks-bucket\"\n",
    "    prefix_path = \"stocks/crypto/\"\n",
    "    year = ''\n",
    "    mont = ''\n",
    "    day = ''\n",
    "    hour = ''\n",
    "    minute = ''\n",
    "    if get_full_file == True:\n",
    "        df_from_file = etl_ingestion.get_full_data_csv_file(bucket_name, prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323f3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_from_file is not None:\n",
    "    df_from_file.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
